{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251ef607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VesselMNIST3D Dataset Analysis\n",
    "# Medical Imaging Dataset Exploration\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # or 'Qt5Agg' depending on your system\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.widgets import Slider\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configure matplotlib fonts\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial', 'Tahoma', 'DejaVu Sans', 'Verdana']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c39a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medmnist import VesselMNIST3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0010af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING VESSELMNIST3D DATASET\n",
      "============================================================\n",
      "\n",
      "Processing training data...\n",
      "Processing test data...\n",
      "Processing validation data...\n",
      "\n",
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LOADING VESSELMNIST3D DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = VesselMNIST3D(split='train', size=28, download=True)\n",
    "test_dataset = VesselMNIST3D(split='test', size=28, download=True)\n",
    "val_dataset = VesselMNIST3D(split='val', size=28, download=True)\n",
    "\n",
    "# Convert to lists\n",
    "trainx = []\n",
    "trainy = []\n",
    "testx = []\n",
    "testy = []\n",
    "valx = []\n",
    "valy = []\n",
    "\n",
    "print(\"\\nProcessing training data...\")\n",
    "for i in range(len(train_dataset)):\n",
    "    trainx.append(train_dataset[i][0])\n",
    "    trainy.append(train_dataset[i][1])\n",
    "\n",
    "print(\"Processing test data...\")\n",
    "for i in range(len(test_dataset)):\n",
    "    testx.append(test_dataset[i][0])\n",
    "    testy.append(test_dataset[i][1])\n",
    "\n",
    "print(\"Processing validation data...\")\n",
    "for i in range(len(val_dataset)):\n",
    "    valx.append(val_dataset[i][0])\n",
    "    valy.append(val_dataset[i][1])\n",
    "\n",
    "# Convert to tensors\n",
    "trainx_tensor = tf.convert_to_tensor(trainx, dtype=tf.float16)\n",
    "trainy_tensor = tf.convert_to_tensor(trainy, dtype=tf.float16)\n",
    "testx_tensor = tf.convert_to_tensor(testx, dtype=tf.float16)\n",
    "testy_tensor = tf.convert_to_tensor(testy, dtype=tf.float16)\n",
    "valx_tensor = tf.convert_to_tensor(valx, dtype=tf.float16)\n",
    "valy_tensor = tf.convert_to_tensor(valy, dtype=tf.float16)\n",
    "\n",
    "print(\"\\nDataset loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94911c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET STATISTICS\n",
      "============================================================\n",
      "Training samples: 1335\n",
      "Test samples: 382\n",
      "Validation samples: 191\n",
      "\n",
      "Input shape: (1335, 1, 28, 28, 28)\n",
      "Label shape: (1335, 1)\n",
      "\n",
      "Single image shape: (1, 28, 28, 28)\n",
      "Data type: <dtype: 'float16'>\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 1: DATASET STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"\\nInput shape: {trainx_tensor.shape}\")\n",
    "print(f\"Label shape: {trainy_tensor.shape}\")\n",
    "print(f\"\\nSingle image shape: {trainx[0].shape}\")\n",
    "print(f\"Data type: {trainx_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "735d01d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LABEL DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "Training set class distribution:\n",
      "  Class 0: 1185 samples (88.76%)\n",
      "  Class 1: 150 samples (11.24%)\n",
      "\n",
      "Test set class distribution:\n",
      "  Class 0: 339 samples (88.74%)\n",
      "  Class 1: 43 samples (11.26%)\n",
      "\n",
      "Validation set class distribution:\n",
      "  Class 0: 169 samples (88.48%)\n",
      "  Class 1: 22 samples (11.52%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 2: LABEL DISTRIBUTION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LABEL DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Training set\n",
    "unique_train, counts_train = np.unique(trainy, return_counts=True)\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "for label, count in zip(unique_train, counts_train):\n",
    "    percentage = (count / len(trainy)) * 100\n",
    "    print(f\"  Class {label}: {count} samples ({percentage:.2f}%)\")  # Remove [0]\n",
    "\n",
    "# Test set\n",
    "unique_test, counts_test = np.unique(testy, return_counts=True)\n",
    "print(\"\\nTest set class distribution:\")\n",
    "for label, count in zip(unique_test, counts_test):\n",
    "    percentage = (count / len(testy)) * 100\n",
    "    print(f\"  Class {label}: {count} samples ({percentage:.2f}%)\")  # Remove [0]\n",
    "\n",
    "# Validation set\n",
    "unique_val, counts_val = np.unique(valy, return_counts=True)\n",
    "print(\"\\nValidation set class distribution:\")\n",
    "for label, count in zip(unique_val, counts_val):\n",
    "    percentage = (count / len(valy)) * 100\n",
    "    print(f\"  Class {label}: {count} samples ({percentage:.2f}%)\")  # Remove [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29e3c1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA VALUE RANGES\n",
      "============================================================\n",
      "Min value: 0.0\n",
      "Max value: 1.0\n",
      "Mean value: 0.0374\n",
      "Std deviation: 0.1896\n",
      "\n",
      "Data range: [0.0, 1.0]\n",
      "\n",
      "============================================================\n",
      "MEMORY USAGE\n",
      "============================================================\n",
      "Training data: 55.90 MB\n",
      "Test data: 15.99 MB\n",
      "Validation data: 8.00 MB\n",
      "Total: 79.89 MB\n",
      "\n",
      "Using float16 saves ~50% memory compared to float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: DATA VALUE RANGE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA VALUE RANGES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sample_vol = np.array(trainx[0])\n",
    "print(f\"Min value: {sample_vol.min()}\")\n",
    "print(f\"Max value: {sample_vol.max()}\")\n",
    "print(f\"Mean value: {sample_vol.mean():.4f}\")\n",
    "print(f\"Std deviation: {sample_vol.std():.4f}\")\n",
    "\n",
    "print(f\"\\nData range: [{sample_vol.min()}, {sample_vol.max()}]\")\n",
    "if sample_vol.max() > 1.0:\n",
    "    print(\"Note: Data may need normalization for neural network training\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: MEMORY USAGE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "\n",
    "trainx_size_mb = sys.getsizeof(trainx_tensor.numpy()) / (1024**2)\n",
    "testx_size_mb = sys.getsizeof(testx_tensor.numpy()) / (1024**2)\n",
    "valx_size_mb = sys.getsizeof(valx_tensor.numpy()) / (1024**2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MEMORY USAGE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training data: {trainx_size_mb:.2f} MB\")\n",
    "print(f\"Test data: {testx_size_mb:.2f} MB\")\n",
    "print(f\"Validation data: {valx_size_mb:.2f} MB\")\n",
    "print(f\"Total: {trainx_size_mb + testx_size_mb + valx_size_mb:.2f} MB\")\n",
    "print(f\"\\nUsing float16 saves ~50% memory compared to float32\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a56254a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GENERATING VISUALIZATIONS...\n",
      "============================================================\n",
      "\n",
      "Class imbalance ratio: 7.90:1\n",
      "⚠️  Significant class imbalance detected!\n",
      "   Consider using class weights or data augmentation during training.\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE!\n",
      "============================================================\n",
      "\n",
      "All visualizations have been generated and saved.\n",
      "Check the current directory for PNG files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 1: CLASS DISTRIBUTION BAR CHART\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATING VISUALIZATIONS...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(unique_train.flatten(), counts_train, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "plt.xlabel('Class Label', fontsize=12)\n",
    "plt.ylabel('Number of Samples', fontsize=12)\n",
    "plt.title('Class Distribution in Training Set', fontsize=14, fontweight='bold')\n",
    "plt.xticks(unique_train.flatten())\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar, count in zip(bars, counts_train):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{count}',\n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "# print(\"✓ Saved: class_distribution.png\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "max_count = counts_train.max()\n",
    "min_count = counts_train.min()\n",
    "imbalance_ratio = max_count / min_count\n",
    "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"⚠️  Significant class imbalance detected!\")\n",
    "    print(\"   Consider using class weights or data augmentation during training.\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 2: VOXEL INTENSITY HISTOGRAM\n",
    "# ============================================================================\n",
    "\n",
    "sample_vol = np.array(trainx[0]).squeeze()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(sample_vol.flatten(), bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "plt.xlabel('Voxel Intensity', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Voxel Intensities (Sample Volume)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('voxel_intensity_histogram.png', dpi=150, bbox_inches='tight')\n",
    "# print(\"✓ Saved: voxel_intensity_histogram.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 3: SAMPLES FROM EACH CLASS\n",
    "# ============================================================================\n",
    "\n",
    "# Get one example from each class\n",
    "class_examples = {}\n",
    "for i, label in enumerate(trainy):\n",
    "    class_label = label[0]\n",
    "    if class_label not in class_examples:\n",
    "        class_examples[class_label] = i\n",
    "    if len(class_examples) == len(np.unique(trainy)):\n",
    "        break\n",
    "\n",
    "num_classes = len(class_examples)\n",
    "fig, axes = plt.subplots(1, num_classes, figsize=(4*num_classes, 4))\n",
    "\n",
    "if num_classes == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, (class_label, sample_idx) in enumerate(class_examples.items()):\n",
    "    vol = np.array(trainx[sample_idx]).squeeze()\n",
    "    mid_slice = vol.shape[0] // 2\n",
    "    \n",
    "    axes[idx].imshow(vol[mid_slice], cmap='gray')\n",
    "    axes[idx].set_title(f'Class {class_label}\\n(Sample {sample_idx})', fontsize=12)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Middle Slice from Each Class', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('class_examples.png', dpi=150, bbox_inches='tight')\n",
    "# print(\"✓ Saved: class_examples.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 4: ORTHOGONAL VIEWS (AXIAL, CORONAL, SAGITTAL)\n",
    "# ============================================================================\n",
    "\n",
    "vol = np.array(trainx[1]).squeeze()\n",
    "\n",
    "i_mid = vol.shape[0] // 2\n",
    "j_mid = vol.shape[1] // 2\n",
    "k_mid = vol.shape[2] // 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axes[0].imshow(vol[i_mid, :, :], cmap='gray')\n",
    "axes[0].set_title(f'Axial View (slice {i_mid})', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(vol[:, j_mid, :], cmap='gray')\n",
    "axes[1].set_title(f'Coronal View (slice {j_mid})', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(vol[:, :, k_mid], cmap='gray')\n",
    "axes[2].set_title(f'Sagittal View (slice {k_mid})', fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle('Orthogonal Views of 3D Volume', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('orthogonal_views.png', dpi=150, bbox_inches='tight')\n",
    "# print(\"✓ Saved: orthogonal_views.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 5: ALL SLICES GRID\n",
    "# ============================================================================\n",
    "\n",
    "num_slices = vol.shape[0]\n",
    "rows, cols = 7, 4\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 18))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < num_slices:\n",
    "        ax.imshow(vol[i], cmap='gray')\n",
    "        ax.set_title(f\"Slice {i}\", fontsize=10)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle('All Slices of Sample Volume', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('all_slices_grid.png', dpi=150, bbox_inches='tight')\n",
    "# print(\"✓ Saved: all_slices_grid.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 6: MULTIPLE SAMPLES COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "num_samples = 4\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
    "\n",
    "random_indices = np.random.choice(len(trainx), num_samples, replace=False)\n",
    "\n",
    "for row, idx in enumerate(random_indices):\n",
    "    vol = np.array(trainx[idx]).squeeze()\n",
    "    label = trainy[idx][0]\n",
    "    \n",
    "    slice_indices = [vol.shape[0]//4, vol.shape[0]//2, 3*vol.shape[0]//4]\n",
    "    \n",
    "    for col, slice_idx in enumerate(slice_indices):\n",
    "        axes[row, col].imshow(vol[slice_idx], cmap='gray')\n",
    "        if row == 0:\n",
    "            axes[row, col].set_title(f'Slice {slice_idx}', fontsize=11)\n",
    "        if col == 0:\n",
    "            axes[row, col].set_ylabel(f'Sample {idx}\\nClass {label}', \n",
    "                                      fontsize=10, rotation=0, \n",
    "                                      ha='right', va='center')\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Multiple Samples at Different Slice Positions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('multiple_samples_comparison.png', dpi=150, bbox_inches='tight')\n",
    "# print(\"✓ Saved: multiple_samples_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 7: 3D VOXEL PLOT\n",
    "# ============================================================================\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "vol = np.squeeze(trainx[1], axis=0)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "filled = vol > 0\n",
    "\n",
    "norm = colors.Normalize(vmin=vol.min(), vmax=vol.max())\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "facecolors = cmap(norm(vol))\n",
    "\n",
    "alpha = np.clip(vol, 0, 1)\n",
    "facecolors[..., 3] = alpha\n",
    "facecolors[~filled, 3] = 0.0\n",
    "\n",
    "ax.voxels(filled, facecolors=facecolors)\n",
    "\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "plt.title('3D Voxel Visualization with Magnitude-Based Transparency', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('3d_voxel_plot.png', dpi=150, bbox_inches='tight')\n",
    "# print(\"✓ Saved: 3d_voxel_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nAll visualizations have been generated and saved.\")\n",
    "print(\"Check the current directory for PNG files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee8b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
