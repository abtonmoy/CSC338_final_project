{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45468f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # or 'Qt5Agg' \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.widgets import Slider\n",
    "import tensorflow as tf\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial', 'Tahoma', 'DejaVu Sans', 'Verdana']\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684262f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medmnist import VesselMNIST3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5baca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_dataset = VesselMNIST3D(split='train', size=28, download=True)\n",
    "trainx = []\n",
    "trainy = []\n",
    "\n",
    "test_dataset = VesselMNIST3D(split='test', size=28, download=True)\n",
    "testx = []\n",
    "testy = []\n",
    "\n",
    "val_dataset = VesselMNIST3D(split='train', size=28, download=True)\n",
    "valx = []\n",
    "valy = []\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    trainx.append(train_dataset[i][0])\n",
    "    trainy.append(train_dataset[i][1])\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    testx.append(test_dataset[i][0])\n",
    "    testy.append(test_dataset[i][1])\n",
    "\n",
    "for i in range(len(val_dataset)):\n",
    "    valx.append(val_dataset[i][0])\n",
    "    valy.append(val_dataset[i][1])\n",
    "\n",
    "trainx_tensor = tf.convert_to_tensor(trainx, dtype=tf.float16)\n",
    "trainy_tensor = tf.convert_to_tensor(trainy, dtype=tf.float16)\n",
    "testx_tensor = tf.convert_to_tensor(testx, dtype=tf.float16)\n",
    "testy_tensor = tf.convert_to_tensor(testy, dtype=tf.float16)\n",
    "valx_tensor = tf.convert_to_tensor(valx, dtype=tf.float16)\n",
    "valy_tensor = tf.convert_to_tensor(valy, dtype=tf.float16)\n",
    "# float16 doesn't run any faster on the 4090s, but it cuts memory usage in half!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f27f4",
   "metadata": {},
   "source": [
    "Dataset Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba0a1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1335\n",
      "Test samples: 382\n",
      "Validation samples: 1335\n",
      "\n",
      "Input shape: (1335, 1, 28, 28, 28)\n",
      "Label shape: (1335, 1)\n",
      "\n",
      "Single image shape: (1, 28, 28, 28)\n",
      "Data type: <dtype: 'float16'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"\\nInput shape: {trainx_tensor.shape}\")\n",
    "print(f\"Label shape: {trainy_tensor.shape}\")\n",
    "print(f\"\\nSingle image shape: {trainx[0].shape}\")\n",
    "print(f\"Data type: {trainx_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15548a96",
   "metadata": {},
   "source": [
    "Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06a238fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set class distribution:\n",
      "  Class 0: 1185 samples (88.76%)\n",
      "  Class 1: 150 samples (11.24%)\n",
      "\n",
      "Test set class distribution:\n",
      "  Class 0: 339 samples (88.74%)\n",
      "  Class 1: 43 samples (11.26%)\n",
      "\n",
      "Validation set class distribution:\n",
      "  Class 0: 1185 samples (88.76%)\n",
      "  Class 1: 150 samples (11.24%)\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "unique_train, counts_train = np.unique(trainy, return_counts=True)\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "for label, count in zip(unique_train, counts_train):\n",
    "    percentage = (count / len(trainy)) * 100\n",
    "    print(f\"  Class {label}: {count} samples ({percentage:.2f}%)\")  # Remove [0]\n",
    "\n",
    "# Test set\n",
    "unique_test, counts_test = np.unique(testy, return_counts=True)\n",
    "print(\"\\nTest set class distribution:\")\n",
    "for label, count in zip(unique_test, counts_test):\n",
    "    percentage = (count / len(testy)) * 100\n",
    "    print(f\"  Class {label}: {count} samples ({percentage:.2f}%)\")  # Remove [0]\n",
    "\n",
    "# Validation set\n",
    "unique_val, counts_val = np.unique(valy, return_counts=True)\n",
    "print(\"\\nValidation set class distribution:\")\n",
    "for label, count in zip(unique_val, counts_val):\n",
    "    percentage = (count / len(valy)) * 100\n",
    "    print(f\"  Class {label}: {count} samples ({percentage:.2f}%)\")  # Remove [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3c809",
   "metadata": {},
   "source": [
    "Range analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fc2c4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value: 0.0\n",
      "Max value: 1.0\n",
      "Mean value: 0.0374\n",
      "Std deviation: 0.1896\n",
      "\n",
      "Data range: [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "sample_vol = np.array(trainx[0])\n",
    "print(f\"Min value: {sample_vol.min()}\")\n",
    "print(f\"Max value: {sample_vol.max()}\")\n",
    "print(f\"Mean value: {sample_vol.mean():.4f}\")\n",
    "print(f\"Std deviation: {sample_vol.std():.4f}\")\n",
    "\n",
    "print(f\"\\nData range: [{sample_vol.min()}, {sample_vol.max()}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820bcd13",
   "metadata": {},
   "source": [
    "Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91874985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 55.90 MB\n",
      "Test data: 15.99 MB\n",
      "Validation data: 55.90 MB\n",
      "Total: 127.79 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainx_size_mb = sys.getsizeof(trainx_tensor.numpy()) / (1024**2)\n",
    "testx_size_mb = sys.getsizeof(testx_tensor.numpy()) / (1024**2)\n",
    "valx_size_mb = sys.getsizeof(valx_tensor.numpy()) / (1024**2)\n",
    "\n",
    "\n",
    "print(f\"Training data: {trainx_size_mb:.2f} MB\")\n",
    "print(f\"Test data: {testx_size_mb:.2f} MB\")\n",
    "print(f\"Validation data: {valx_size_mb:.2f} MB\")\n",
    "print(f\"Total: {trainx_size_mb + testx_size_mb + valx_size_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439f488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
