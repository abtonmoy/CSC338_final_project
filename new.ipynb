{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c7823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.widgets import Slider\n",
    "import matplotlib\n",
    "import matplotlib.font_manager\n",
    "\n",
    "from medmnist import VesselMNIST3D\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Available devices:\", tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VesselMNIST3D(split='train', size=28, download=True)\n",
    "trainx = []\n",
    "trainy = []\n",
    "\n",
    "test_dataset = VesselMNIST3D(split='test', size=28, download=True)\n",
    "testx = []\n",
    "testy = []\n",
    "\n",
    "val_dataset = VesselMNIST3D(split='val', size=28, download=True)  # Fixed: was 'train'\n",
    "valx = []\n",
    "valy = []\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    trainx.append(train_dataset[i][0])\n",
    "    trainy.append(train_dataset[i][1])\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    testx.append(test_dataset[i][0])\n",
    "    testy.append(test_dataset[i][1])\n",
    "\n",
    "for i in range(len(val_dataset)):\n",
    "    valx.append(val_dataset[i][0])\n",
    "    valy.append(val_dataset[i][1])\n",
    "\n",
    "trainx_tensor = tf.convert_to_tensor(trainx, dtype=tf.float32)  # Using float32 for now\n",
    "trainy_tensor = tf.convert_to_tensor(trainy, dtype=tf.float32)\n",
    "testx_tensor = tf.convert_to_tensor(testx, dtype=tf.float32)\n",
    "testy_tensor = tf.convert_to_tensor(testy, dtype=tf.float32)\n",
    "valx_tensor = tf.convert_to_tensor(valx, dtype=tf.float32)\n",
    "valy_tensor = tf.convert_to_tensor(valy, dtype=tf.float32)\n",
    "\n",
    "print(f\"\\nData loaded successfully!\")\n",
    "print(f\"Training set: {trainx_tensor.shape}\")\n",
    "print(f\"Validation set: {valx_tensor.shape}\")\n",
    "print(f\"Test set: {testx_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "train_labels = np.array(trainy).flatten()\n",
    "val_labels = np.array(valy).flatten()\n",
    "test_labels = np.array(testy).flatten()\n",
    "\n",
    "unique_train, counts_train = np.unique(train_labels, return_counts=True)\n",
    "unique_val, counts_val = np.unique(val_labels, return_counts=True)\n",
    "unique_test, counts_test = np.unique(test_labels, return_counts=True)\n",
    "\n",
    "print(f\"Training - Class 0 (Healthy): {counts_train[0]}, Class 1 (Aneurysm): {counts_train[1]}\")\n",
    "print(f\"Validation - Class 0 (Healthy): {counts_val[0]}, Class 1 (Aneurysm): {counts_val[1]}\")\n",
    "print(f\"Test - Class 0 (Healthy): {counts_test[0]}, Class 1 (Aneurysm): {counts_test[1]}\")\n",
    "print(f\"\\nClass imbalance ratio (train): {counts_train[1]/counts_train[0]:.3f}\")\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for ax, (name, counts) in zip(axes, \n",
    "    [('Training', counts_train), ('Validation', counts_val), ('Test', counts_test)]):\n",
    "    ax.bar(['Healthy', 'Aneurysm'], counts, color=['steelblue', 'coral'])\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'{name} Set Distribution')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: 3D Voxel Visualization\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "vol = np.squeeze(trainx[1], axis=0)  # shape (28, 28, 28)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "filled = vol > 0\n",
    "norm = colors.Normalize(vmin=vol.min(), vmax=vol.max())\n",
    "cmap = plt.cm.viridis\n",
    "facecolors = cmap(norm(vol))\n",
    "alpha = np.clip(vol, 0, 1)\n",
    "facecolors[..., 3] = alpha\n",
    "facecolors[~filled, 3] = 0.0\n",
    "\n",
    "ax.voxels(filled, facecolors=facecolors)\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "plt.title(f'3D Voxel Visualization - Label: {trainy[1]}')\n",
    "plt.show()\n",
    "\n",
    "# Example 2: Orthogonal Slices (Middle Slices)\n",
    "vol = np.array(trainx[0]).squeeze()\n",
    "i_mid = vol.shape[0] // 2\n",
    "j_mid = vol.shape[1] // 2\n",
    "k_mid = vol.shape[2] // 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(vol[i_mid, :, :], cmap='gray')\n",
    "axes[0].set_title(f'Axial (i={i_mid}) - Label: {trainy[0]}')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(vol[:, j_mid, :], cmap='gray')\n",
    "axes[1].set_title(f'Coronal (j={j_mid})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(vol[:, :, k_mid], cmap='gray')\n",
    "axes[2].set_title(f'Sagittal (k={k_mid})')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Example 3: Show healthy vs aneurysm examples\n",
    "healthy_idx = np.where(train_labels == 0)[0][0]\n",
    "aneurysm_idx = np.where(train_labels == 1)[0][0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "fig.suptitle('Healthy vs Aneurysm Comparison', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Healthy example\n",
    "vol_healthy = np.array(trainx[healthy_idx]).squeeze()\n",
    "mid = vol_healthy.shape[0] // 2\n",
    "axes[0, 0].imshow(vol_healthy[mid, :, :], cmap='gray')\n",
    "axes[0, 0].set_title('Healthy - Axial')\n",
    "axes[0, 0].axis('off')\n",
    "axes[0, 1].imshow(vol_healthy[:, mid, :], cmap='gray')\n",
    "axes[0, 1].set_title('Healthy - Coronal')\n",
    "axes[0, 1].axis('off')\n",
    "axes[0, 2].imshow(vol_healthy[:, :, mid], cmap='gray')\n",
    "axes[0, 2].set_title('Healthy - Sagittal')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Aneurysm example\n",
    "vol_aneurysm = np.array(trainx[aneurysm_idx]).squeeze()\n",
    "mid = vol_aneurysm.shape[0] // 2\n",
    "axes[1, 0].imshow(vol_aneurysm[mid, :, :], cmap='gray')\n",
    "axes[1, 0].set_title('Aneurysm - Axial')\n",
    "axes[1, 0].axis('off')\n",
    "axes[1, 1].imshow(vol_aneurysm[:, mid, :], cmap='gray')\n",
    "axes[1, 1].set_title('Aneurysm - Coronal')\n",
    "axes[1, 1].axis('off')\n",
    "axes[1, 2].imshow(vol_aneurysm[:, :, mid], cmap='gray')\n",
    "axes[1, 2].set_title('Aneurysm - Sagittal')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce50384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data to [0, 1] range\n",
    "trainx_norm = trainx_tensor / 255.0\n",
    "valx_norm = valx_tensor / 255.0\n",
    "testx_norm = testx_tensor / 255.0\n",
    "\n",
    "# Flatten labels\n",
    "trainy_flat = tf.squeeze(trainy_tensor)\n",
    "valy_flat = tf.squeeze(valy_tensor)\n",
    "testy_flat = tf.squeeze(testy_tensor)\n",
    "\n",
    "print(f\"Normalized training data shape: {trainx_norm.shape}\")\n",
    "print(f\"Training labels shape: {trainy_flat.shape}\")\n",
    "print(f\"Data range: [{tf.reduce_min(trainx_norm):.3f}, {tf.reduce_max(trainx_norm):.3f}]\")\n",
    "\n",
    "# Calculate class weights for imbalanced data\n",
    "class_weight = {\n",
    "    0: len(train_labels) / (2 * counts_train[0]),\n",
    "    1: len(train_labels) / (2 * counts_train[1])\n",
    "}\n",
    "print(f\"\\nClass weights to handle imbalance: {class_weight}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Architecture Design Rationale:\n",
    "- 3D Convolutional layers to capture spatial relationships in volumetric data\n",
    "- Progressive downsampling (28â†’14â†’7â†’3) to build hierarchical features\n",
    "- Batch normalization for training stability\n",
    "- Dropout for regularization (critical for small dataset)\n",
    "- Dense layers for final classification\n",
    "- Sigmoid activation for binary classification\n",
    "\n",
    "The architecture processes the 3D volume through multiple convolutional blocks,\n",
    "each extracting increasingly abstract features before making a classification.\n",
    "\"\"\"\n",
    "\n",
    "def build_3d_cnn(input_shape=(28, 28, 28, 1), dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    Build a 3D CNN for binary classification of vessel segments\n",
    "    \n",
    "    Parameters:\n",
    "    - input_shape: Shape of input 3D volume with channel\n",
    "    - dropout_rate: Dropout probability for regularization\n",
    "    \n",
    "    Returns:\n",
    "    - Compiled Keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=input_shape),\n",
    "        \n",
    "        # Block 1: Initial feature extraction (28x28x28 â†’ 14x14x14)\n",
    "        layers.Conv3D(32, kernel_size=(3, 3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        \n",
    "        # Block 2: Deeper features (14x14x14 â†’ 7x7x7)\n",
    "        layers.Conv3D(64, kernel_size=(3, 3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        \n",
    "        # Block 3: High-level features (7x7x7 â†’ 3x3x3)\n",
    "        layers.Conv3D(128, kernel_size=(3, 3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        \n",
    "        # Global pooling to reduce parameters\n",
    "        layers.GlobalAveragePooling3D(),\n",
    "        \n",
    "        # Dense layers for classification\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        \n",
    "        # Output layer (sigmoid for binary classification)\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and display model\n",
    "model = build_3d_cnn(input_shape=(28, 28, 28, 1), dropout_rate=0.3)\n",
    "model.summary()\n",
    "\n",
    "print(\"\\nTotal parameters:\", model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loss Function: Binary Crossentropy\n",
    "- Standard for binary classification tasks\n",
    "- Measures difference between predicted and actual probabilities\n",
    "\n",
    "Optimizer: Adam\n",
    "- Adaptive learning rate optimizer\n",
    "- Works well with default parameters for most problems\n",
    "\n",
    "Metrics:\n",
    "- Accuracy: Overall correctness\n",
    "- AUC: Area Under ROC Curve - crucial for imbalanced medical datasets\n",
    "  Measures the model's ability to distinguish between classes\n",
    "\"\"\"\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "print(\"Model compiled with:\")\n",
    "print(\"- Optimizer: Adam (lr=0.001)\")\n",
    "print(\"- Loss: Binary Crossentropy\")\n",
    "print(\"- Metrics: Accuracy, AUC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b5b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce learning rate when validation loss plateaus\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save best model\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'best_vessel_model.h5',\n",
    "    monitor='val_auc',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nCallbacks configured:\")\n",
    "print(\"- Early Stopping: patience=15, monitor=val_auc\")\n",
    "print(\"- ReduceLROnPlateau: factor=0.5, patience=5\")\n",
    "print(\"- ModelCheckpoint: saves best val_auc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 2 epochs to confirm the model is working\n",
    "history = model.fit(\n",
    "    trainx_norm, trainy_flat,\n",
    "    batch_size=16,\n",
    "    epochs=2,\n",
    "    validation_data=(valx_norm, valy_flat),\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INITIAL TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Epoch 1 â†’ Training Loss: {history.history['loss'][0]:.4f}, \"\n",
    "      f\"Val Loss: {history.history['val_loss'][0]:.4f}\")\n",
    "print(f\"Epoch 2 â†’ Training Loss: {history.history['loss'][1]:.4f}, \"\n",
    "      f\"Val Loss: {history.history['val_loss'][1]:.4f}\")\n",
    "print(f\"\\nTraining AUC: {history.history['auc'][-1]:.4f}\")\n",
    "print(f\"Validation AUC: {history.history['val_auc'][-1]:.4f}\")\n",
    "\n",
    "# Check if loss is decreasing (sign of learning)\n",
    "if history.history['loss'][1] < history.history['loss'][0]:\n",
    "    print(\"\\n Loss is decreasing - model is learning!\")\n",
    "else:\n",
    "    print(\"\\n Loss not decreasing - may need to adjust hyperparameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdeec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting full training session...\")\n",
    "\n",
    "# For GPU: can use float16 to save memory\n",
    "# trainx_tensor = tf.cast(trainx_tensor, tf.float16) / 255.0\n",
    "# valx_tensor = tf.cast(valx_tensor, tf.float16) / 255.0\n",
    "# model = build_3d_cnn(input_shape=(28, 28, 28, 1), dropout_rate=0.3)\n",
    "# model.compile(...) # recompile for float16\n",
    "\n",
    "history_full = model.fit(\n",
    "    trainx_norm, trainy_flat,\n",
    "    batch_size=32,  # Larger batch for GPU\n",
    "    epochs=100,  # Will stop early with callback\n",
    "    validation_data=(valx_norm, valy_flat),\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history_full.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(history_full.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Model Loss Over Time')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history_full.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[1].plot(history_full.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Model Accuracy Over Time')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# AUC\n",
    "axes[2].plot(history_full.history['auc'], label='Training AUC', linewidth=2)\n",
    "axes[2].plot(history_full.history['val_auc'], label='Validation AUC', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('AUC')\n",
    "axes[2].set_title('Model AUC Over Time')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe898a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load best model\n",
    "model = keras.models.load_model('best_vessel_model.h5')\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(testx_norm, testy_flat, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_proba = model.predict(testx_norm, verbose=0)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, y_pred, \n",
    "                          target_names=['Healthy', 'Aneurysm'],\n",
    "                          digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Healthy', 'Aneurysm'],\n",
    "            yticklabels=['Healthy', 'Aneurysm'])\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_labels, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'Model (AUC = {test_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON WITH MEDMNIST BENCHMARKS\")\n",
    "print(\"=\"*70)\n",
    "print(\"VesselMNIST3D Baseline Performance (from MedMNIST paper):\")\n",
    "print(\"- ResNet18 (3D): AUC ~0.920, ACC ~0.890\")\n",
    "print(\"- Auto-sklearn: AUC ~0.917, ACC ~0.887\")\n",
    "print(\"\\nYour Model Performance:\")\n",
    "print(f\"- Test AUC: {test_auc:.4f}\")\n",
    "print(f\"- Test ACC: {test_acc:.4f}\")\n",
    "\n",
    "if test_auc >= 0.920:\n",
    "    print(\"\\nðŸŽ‰ Excellent! Your model matches or exceeds the baseline!\")\n",
    "elif test_auc >= 0.900:\n",
    "    print(\"\\nâœ“ Good performance! Close to the baseline.\")\n",
    "else:\n",
    "    print(\"\\nâ†’ Room for improvement. Consider:\")\n",
    "    print(\"  - Data augmentation (rotations, flips)\")\n",
    "    print(\"  - Deeper architecture or residual connections\")\n",
    "    print(\"  - Different regularization strategies\")\n",
    "    print(\"  - Ensemble methods\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
