{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7449fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def inception_block_3d(x, filters):\n",
    "    \"\"\"3D Inception module with multiple kernel sizes\"\"\"\n",
    "    # 1x1x1 convolution branch\n",
    "    branch1 = layers.Conv3D(filters, (1, 1, 1), padding='same', activation='relu')(x)\n",
    "    \n",
    "    # 3x3x3 convolution branch\n",
    "    branch2 = layers.Conv3D(filters, (1, 1, 1), padding='same', activation='relu')(x)\n",
    "    branch2 = layers.Conv3D(filters, (3, 3, 3), padding='same', activation='relu')(branch2)\n",
    "    \n",
    "    # 5x5x5 convolution branch (implemented as two 3x3x3)\n",
    "    branch3 = layers.Conv3D(filters, (1, 1, 1), padding='same', activation='relu')(x)\n",
    "    branch3 = layers.Conv3D(filters, (3, 3, 3), padding='same', activation='relu')(branch3)\n",
    "    branch3 = layers.Conv3D(filters, (3, 3, 3), padding='same', activation='relu')(branch3)\n",
    "    \n",
    "    # Pooling branch\n",
    "    branch4 = layers.MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same')(x)\n",
    "    branch4 = layers.Conv3D(filters, (1, 1, 1), padding='same', activation='relu')(branch4)\n",
    "    \n",
    "    # Concatenate all branches\n",
    "    output = layers.Concatenate()([branch1, branch2, branch3, branch4])\n",
    "    return output\n",
    "\n",
    "def residual_block_3d(x, filters):\n",
    "    \"\"\"3D Residual block with skip connection\"\"\"\n",
    "    shortcut = x\n",
    "    \n",
    "    # Main path\n",
    "    x = layers.Conv3D(filters, (3, 3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv3D(filters, (3, 3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Adjust shortcut dimensions if needed\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv3D(filters, (1, 1, 1), padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    \n",
    "    # Add shortcut\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def squeeze_excitation_block_3d(x, ratio=16):\n",
    "    \"\"\"3D Squeeze-and-Excitation block for channel attention\"\"\"\n",
    "    channels = x.shape[-1]\n",
    "    \n",
    "    # Squeeze: global average pooling\n",
    "    se = layers.GlobalAveragePooling3D()(x)\n",
    "    \n",
    "    # Excitation: FC layers\n",
    "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
    "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
    "    \n",
    "    # Reshape and scale\n",
    "    se = layers.Reshape((1, 1, 1, channels))(se)\n",
    "    return layers.Multiply()([x, se])\n",
    "\n",
    "def MyNet3D(num_classes=2):\n",
    "    \"\"\"\n",
    "    3D Neural Network for VesselMNIST3D\n",
    "    \n",
    "    This architecture adapts the 2D hybrid design for 3D medical imaging:\n",
    "    - Inception modules for multi-scale feature extraction\n",
    "    - Residual connections for deep learning\n",
    "    - Squeeze-and-Excitation for channel attention\n",
    "    - Dense connections across stages\n",
    "    - Dual attention mechanism\n",
    "    \n",
    "    Args:\n",
    "        num_classes: Number of output classes (check your dataset)\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = layers.Input(shape=(28, 28, 28, 1))\n",
    "    \n",
    "    # 3D Data augmentation (applied during training only)\n",
    "    x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    x = layers.RandomRotation(0.1, fill_mode='nearest')(x)\n",
    "    x = layers.RandomZoom(0.05, fill_mode='nearest')(x)\n",
    "    x = layers.RandomContrast(0.1)(x)\n",
    "    \n",
    "    # Initial feature extraction - reduced filters for 3D\n",
    "    x = layers.Conv3D(16, (3, 3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Stage 1: Multi-scale feature extraction at 28x28x28 resolution\n",
    "    inception1 = inception_block_3d(x, 8)\n",
    "    inception1 = layers.BatchNormalization()(inception1)\n",
    "    inception1 = layers.Dropout(0.2)(inception1)\n",
    "    \n",
    "    residual1 = residual_block_3d(inception1, 32)\n",
    "    se1 = squeeze_excitation_block_3d(residual1)\n",
    "    \n",
    "    # Reduce spatial dimensions to 14x14x14\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(se1)\n",
    "    \n",
    "    # Stage 2: Deeper feature learning at 14x14x14 resolution\n",
    "    inception2 = inception_block_3d(x, 12)\n",
    "    inception2 = layers.BatchNormalization()(inception2)\n",
    "    inception2 = layers.Dropout(0.3)(inception2)\n",
    "    \n",
    "    residual2 = residual_block_3d(inception2, 48)\n",
    "    se2 = squeeze_excitation_block_3d(residual2)\n",
    "    \n",
    "    # Dense connection: add features from stage 1 to stage 2\n",
    "    se1_pooled = layers.MaxPooling3D((2, 2, 2))(se1)\n",
    "    se1_adjusted = layers.Conv3D(48, (1, 1, 1), padding='same')(se1_pooled)\n",
    "    dense_concat1 = layers.Add()([se2, se1_adjusted])\n",
    "    \n",
    "    # Reduce spatial dimensions to 7x7x7\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(dense_concat1)\n",
    "    \n",
    "    # Stage 3: Deep feature processing at 7x7x7 resolution\n",
    "    residual3a = residual_block_3d(x, 64)\n",
    "    residual3a = layers.Dropout(0.35)(residual3a)\n",
    "    \n",
    "    residual3b = residual_block_3d(residual3a, 64)\n",
    "    se3 = squeeze_excitation_block_3d(residual3b)\n",
    "    \n",
    "    # Dual attention mechanism\n",
    "    # Path A: spatial attention\n",
    "    spatial_attention = layers.Conv3D(1, (7, 7, 7), padding='same', activation='sigmoid')(se3)\n",
    "    spatial_features = layers.Multiply()([se3, spatial_attention])\n",
    "    \n",
    "    # Path B: channel-wise transformation\n",
    "    channel_features = layers.Conv3D(64, (1, 1, 1), activation='relu')(se3)\n",
    "    \n",
    "    # Combine both attention paths\n",
    "    x = layers.Concatenate()([spatial_features, channel_features])\n",
    "    x = layers.Conv3D(128, (1, 1, 1), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    # Final feature compression\n",
    "    x = layers.Conv3D(96, (3, 3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Multi-scale global pooling\n",
    "    gap = layers.GlobalAveragePooling3D()(x)\n",
    "    gmp = layers.GlobalMaxPooling3D()(x)\n",
    "    x = layers.Concatenate()([gap, gmp])\n",
    "    \n",
    "    # Classification head\n",
    "    x = layers.Dense(192, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(96, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# model = MyNet3D(num_classes=2)  # Adjust num_classes based on VesselMNIST3D\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
