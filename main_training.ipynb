{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "566d3fd1",
   "metadata": {},
   "source": [
    "VesselMNIST3D Test Training Notebook - WITH CUSTOM 3D AUGMENTATION\n",
    "Complete implementation with working 3D data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from medmnist import VesselMNIST3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aba63b",
   "metadata": {},
   "source": [
    "CUSTOM 3D AUGMENTATION LAYER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01fbe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augment3D(layers.Layer):\n",
    "    \"\"\"Custom 3D data augmentation layer for volumetric medical images\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 flip_prob=0.5,\n",
    "                 rotate_prob=0.3,\n",
    "                 brightness_delta=0.1,\n",
    "                 contrast_range=(0.9, 1.1),\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.flip_prob = flip_prob\n",
    "        self.rotate_prob = rotate_prob\n",
    "        self.brightness_delta = brightness_delta\n",
    "        self.contrast_range = contrast_range\n",
    "    \n",
    "    def call(self, images, training=None):\n",
    "        # Default to False if training is not specified\n",
    "        if training is None:\n",
    "            training = False\n",
    "        \n",
    "        # Only augment during training\n",
    "        if not training:\n",
    "            return images\n",
    "        \n",
    "        x = images\n",
    "        \n",
    "        # Random flips along different axes (depth, height, width)\n",
    "        # Each flip is independent with flip_prob\n",
    "        x = tf.cond(\n",
    "            tf.random.uniform([]) < self.flip_prob,\n",
    "            lambda: tf.reverse(x, axis=[1]),  # Flip along depth\n",
    "            lambda: x\n",
    "        )\n",
    "        \n",
    "        x = tf.cond(\n",
    "            tf.random.uniform([]) < self.flip_prob,\n",
    "            lambda: tf.reverse(x, axis=[2]),  # Flip along height\n",
    "            lambda: x\n",
    "        )\n",
    "        \n",
    "        x = tf.cond(\n",
    "            tf.random.uniform([]) < self.flip_prob,\n",
    "            lambda: tf.reverse(x, axis=[3]),  # Flip along width\n",
    "            lambda: x\n",
    "        )\n",
    "        \n",
    "        # Random 90-degree rotations in the XY plane (around Z axis)\n",
    "        # Use tf.switch_case for multiple rotation options\n",
    "        k = tf.random.uniform([], 0, 4, dtype=tf.int32)\n",
    "        \n",
    "        def rotate_0():\n",
    "            return x\n",
    "        \n",
    "        def rotate_90():\n",
    "            rotated = tf.transpose(x, [0, 1, 3, 2, 4])  # Swap H and W\n",
    "            return tf.reverse(rotated, axis=[2])  # Flip to complete rotation\n",
    "        \n",
    "        def rotate_180():\n",
    "            return tf.reverse(x, axis=[2, 3])\n",
    "        \n",
    "        def rotate_270():\n",
    "            rotated = tf.transpose(x, [0, 1, 3, 2, 4])  # Swap H and W\n",
    "            return tf.reverse(rotated, axis=[3])  # Flip to complete rotation\n",
    "        \n",
    "        x = tf.cond(\n",
    "            tf.random.uniform([]) < self.rotate_prob,\n",
    "            lambda: tf.switch_case(k, {0: rotate_0, 1: rotate_90, 2: rotate_180, 3: rotate_270}),\n",
    "            lambda: x\n",
    "        )\n",
    "        \n",
    "        # Random brightness adjustment\n",
    "        delta = tf.random.uniform([], -self.brightness_delta, self.brightness_delta)\n",
    "        x = tf.cond(\n",
    "            tf.random.uniform([]) < 0.5,\n",
    "            lambda: x + delta,\n",
    "            lambda: x\n",
    "        )\n",
    "        \n",
    "        # Random contrast adjustment\n",
    "        factor = tf.random.uniform([], self.contrast_range[0], self.contrast_range[1])\n",
    "        mean = tf.reduce_mean(x, axis=[1, 2, 3, 4], keepdims=True)\n",
    "        x = tf.cond(\n",
    "            tf.random.uniform([]) < 0.5,\n",
    "            lambda: (x - mean) * factor + mean,\n",
    "            lambda: x\n",
    "        )\n",
    "        \n",
    "        # Clip values to valid range [0, 1]\n",
    "        x = tf.clip_by_value(x, 0.0, 1.0)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"Output shape is same as input shape\"\"\"\n",
    "        return input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'flip_prob': self.flip_prob,\n",
    "            'rotate_prob': self.rotate_prob,\n",
    "            'brightness_delta': self.brightness_delta,\n",
    "            'contrast_range': self.contrast_range,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a052dcd",
   "metadata": {},
   "source": [
    "PART 1: BUILDING BLOCKS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block_3d(x, filters):\n",
    "    \"\"\"3D Inception module with multiple kernel sizes\"\"\"\n",
    "    branch1 = layers.Conv3D(filters, (1, 1, 1), padding='same', activation='relu')(x)\n",
    "    \n",
    "    branch2 = layers.Conv3D(filters, (1, 1, 1), padding='same', activation='relu')(x)\n",
    "    branch2 = layers.Conv3D(filters, (3, 3, 3), padding='same', activation='relu')(branch2)\n",
    "    \n",
    "    branch3 = layers.Conv3D(filters, (1, 1, 1), padding='same', activation='relu')(x)\n",
    "    branch3 = layers.Conv3D(filters, (3, 3, 3), padding='same', activation='relu')(branch3)\n",
    "    branch3 = layers.Conv3D(filters, (3, 3, 3), padding='same', activation='relu')(branch3)\n",
    "    \n",
    "    branch4 = layers.MaxPooling3D((3, 3, 3), strides=(1, 1, 1), padding='same')(x)\n",
    "    branch4 = layers.Conv3D(filters, (1, 1, 1), padding='same', activation='relu')(branch4)\n",
    "    \n",
    "    output = layers.Concatenate()([branch1, branch2, branch3, branch4])\n",
    "    return output\n",
    "\n",
    "def residual_block_3d(x, filters):\n",
    "    \"\"\"3D Residual block with skip connection\"\"\"\n",
    "    shortcut = x\n",
    "    \n",
    "    x = layers.Conv3D(filters, (3, 3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv3D(filters, (3, 3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv3D(filters, (1, 1, 1), padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def squeeze_excitation_block_3d(x, ratio=16):\n",
    "    \"\"\"3D Squeeze-and-Excitation block for channel attention\"\"\"\n",
    "    channels = x.shape[-1]\n",
    "    \n",
    "    se = layers.GlobalAveragePooling3D()(x)\n",
    "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
    "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
    "    se = layers.Reshape((1, 1, 1, channels))(se)\n",
    "    \n",
    "    return layers.Multiply()([x, se])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888ab8d",
   "metadata": {},
   "source": [
    "Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fdd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyNet3D(num_classes=2):\n",
    "    \"\"\"Full 3D Network Architecture with Custom 3D Augmentation\"\"\"\n",
    "    inputs = layers.Input(shape=(28, 28, 28, 1))\n",
    "    \n",
    "    # Custom 3D data augmentation (only active during training)\n",
    "    x = Augment3D(\n",
    "        flip_prob=0.5,\n",
    "        rotate_prob=0.3,\n",
    "        brightness_delta=0.1,\n",
    "        contrast_range=(0.9, 1.1)\n",
    "    )(inputs)\n",
    "    \n",
    "    # Initial feature extraction\n",
    "    x = layers.Conv3D(16, (3, 3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Stage 1: 28x28x28\n",
    "    inception1 = inception_block_3d(x, 8)\n",
    "    inception1 = layers.BatchNormalization()(inception1)\n",
    "    inception1 = layers.Dropout(0.2)(inception1)\n",
    "    \n",
    "    residual1 = residual_block_3d(inception1, 32)\n",
    "    se1 = squeeze_excitation_block_3d(residual1)\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(se1)\n",
    "    \n",
    "    # Stage 2: 14x14x14\n",
    "    inception2 = inception_block_3d(x, 12)\n",
    "    inception2 = layers.BatchNormalization()(inception2)\n",
    "    inception2 = layers.Dropout(0.3)(inception2)\n",
    "    \n",
    "    residual2 = residual_block_3d(inception2, 48)\n",
    "    se2 = squeeze_excitation_block_3d(residual2)\n",
    "    \n",
    "    # Dense connection\n",
    "    se1_pooled = layers.MaxPooling3D((2, 2, 2))(se1)\n",
    "    se1_adjusted = layers.Conv3D(48, (1, 1, 1), padding='same')(se1_pooled)\n",
    "    dense_concat1 = layers.Add()([se2, se1_adjusted])\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(dense_concat1)\n",
    "    \n",
    "    # Stage 3: 7x7x7\n",
    "    residual3a = residual_block_3d(x, 64)\n",
    "    residual3a = layers.Dropout(0.35)(residual3a)\n",
    "    \n",
    "    residual3b = residual_block_3d(residual3a, 64)\n",
    "    se3 = squeeze_excitation_block_3d(residual3b)\n",
    "    \n",
    "    # Dual attention\n",
    "    spatial_attention = layers.Conv3D(1, (7, 7, 7), padding='same', activation='sigmoid')(se3)\n",
    "    spatial_features = layers.Multiply()([se3, spatial_attention])\n",
    "    \n",
    "    channel_features = layers.Conv3D(64, (1, 1, 1), activation='relu')(se3)\n",
    "    \n",
    "    x = layers.Concatenate()([spatial_features, channel_features])\n",
    "    x = layers.Conv3D(128, (1, 1, 1), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Conv3D(96, (3, 3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Global pooling\n",
    "    gap = layers.GlobalAveragePooling3D()(x)\n",
    "    gmp = layers.GlobalMaxPooling3D()(x)\n",
    "    x = layers.Concatenate()([gap, gmp])\n",
    "    \n",
    "    # Classification head\n",
    "    x = layers.Dense(192, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(96, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e257e66f",
   "metadata": {},
   "source": [
    "PART 2: DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vesselmnist3d():\n",
    "    \"\"\"\n",
    "    Load VesselMNIST3D dataset\n",
    "    Returns: (train_images, train_labels), (val_images, val_labels), (test_images, test_labels)\n",
    "    \"\"\"\n",
    "    print(\"Loading VesselMNIST3D dataset...\")\n",
    "    \n",
    "    # Download and load the dataset\n",
    "    train_dataset = VesselMNIST3D(split='train', download=True)\n",
    "    val_dataset = VesselMNIST3D(split='val', download=True)\n",
    "    test_dataset = VesselMNIST3D(split='test', download=True)\n",
    "    \n",
    "    # Extract images and labels\n",
    "    train_images = train_dataset.imgs\n",
    "    train_labels = train_dataset.labels.squeeze()\n",
    "    \n",
    "    val_images = val_dataset.imgs\n",
    "    val_labels = val_dataset.labels.squeeze()\n",
    "    \n",
    "    test_images = test_dataset.imgs\n",
    "    test_labels = test_dataset.labels.squeeze()\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    train_images = train_images.astype('float32') / 255.0\n",
    "    val_images = val_images.astype('float32') / 255.0\n",
    "    test_images = test_images.astype('float32') / 255.0\n",
    "    \n",
    "    # Add channel dimension if needed\n",
    "    if len(train_images.shape) == 4:\n",
    "        train_images = np.expand_dims(train_images, axis=-1)\n",
    "        val_images = np.expand_dims(val_images, axis=-1)\n",
    "        test_images = np.expand_dims(test_images, axis=-1)\n",
    "    \n",
    "    print(f\"Train: {train_images.shape}, Labels: {train_labels.shape}\")\n",
    "    print(f\"Val: {val_images.shape}, Labels: {val_labels.shape}\")\n",
    "    print(f\"Test: {test_images.shape}, Labels: {test_labels.shape}\")\n",
    "    print(f\"Number of classes: {len(np.unique(train_labels))}\")\n",
    "    print(f\"Class distribution: {np.bincount(train_labels)}\")\n",
    "    \n",
    "    return (train_images, train_labels), (val_images, val_labels), (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c5342c",
   "metadata": {},
   "source": [
    "PART 3: VISUALIZATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_3d_slice(volume, title=\"3D Volume Slices\"):\n",
    "    \"\"\"\n",
    "    Visualize a 3D volume by showing slices along each axis\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Middle slices along each axis\n",
    "    mid_x = volume.shape[0] // 2\n",
    "    mid_y = volume.shape[1] // 2\n",
    "    mid_z = volume.shape[2] // 2\n",
    "    \n",
    "    axes[0].imshow(volume[mid_x, :, :], cmap='gray')\n",
    "    axes[0].set_title(f'X-axis slice (at x={mid_x})')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(volume[:, mid_y, :], cmap='gray')\n",
    "    axes[1].set_title(f'Y-axis slice (at y={mid_y})')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(volume[:, :, mid_z], cmap='gray')\n",
    "    axes[2].set_title(f'Z-axis slice (at z={mid_z})')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_augmentation_effects(model, sample_image, num_augmentations=6):\n",
    "    \"\"\"\n",
    "    Visualize the effect of data augmentation on a single sample\n",
    "    \"\"\"\n",
    "    # Get the augmentation layer\n",
    "    aug_layer = None\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Augment3D):\n",
    "            aug_layer = layer\n",
    "            break\n",
    "    \n",
    "    if aug_layer is None:\n",
    "        print(\"No augmentation layer found in model\")\n",
    "        return\n",
    "    \n",
    "    # Generate augmented versions\n",
    "    sample_batch = np.expand_dims(sample_image, axis=0)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_augmentations):\n",
    "        # Apply augmentation\n",
    "        augmented = aug_layer(sample_batch, training=True)\n",
    "        augmented_np = augmented.numpy()[0, :, :, :, 0]\n",
    "        \n",
    "        # Show middle slice\n",
    "        mid_z = augmented_np.shape[2] // 2\n",
    "        axes[i].imshow(augmented_np[:, :, mid_z], cmap='gray')\n",
    "        axes[i].set_title(f'Augmented Version {i+1}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Data Augmentation Examples (Middle Z-slice)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[1].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a37358",
   "metadata": {},
   "source": [
    "TEST TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359692dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_test_training():\n",
    "    \"\"\"\n",
    "    Run a quick test with just a few epochs on CPU/local hardware\n",
    "    This is to verify the architecture works before running on GPU\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"QUICK TEST TRAINING - 2 EPOCHS (WITH 3D AUGMENTATION)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load data\n",
    "    (train_images, train_labels), (val_images, val_labels), _ = load_vesselmnist3d()\n",
    "    \n",
    "    # Use only a small subset for quick testing\n",
    "    print(\"\\nUsing small subset for quick testing...\")\n",
    "    train_subset = train_images[:100]\n",
    "    train_labels_subset = train_labels[:100]\n",
    "    val_subset = val_images[:50]\n",
    "    val_labels_subset = val_labels[:50]\n",
    "    \n",
    "    print(f\"Training on {len(train_subset)} samples\")\n",
    "    print(f\"Validating on {len(val_subset)} samples\")\n",
    "    \n",
    "    # Visualize a few samples\n",
    "    print(\"\\nVisualizing sample data...\")\n",
    "    for i in range(2):\n",
    "        visualize_3d_slice(\n",
    "            train_subset[i, :, :, :, 0], \n",
    "            title=f\"Training Sample {i} - Label: {train_labels_subset[i]}\"\n",
    "        )\n",
    "    \n",
    "    # Build model\n",
    "    print(\"\\nBuilding model...\")\n",
    "    num_classes = len(np.unique(train_labels))\n",
    "    model = MyNet3D(num_classes=num_classes)\n",
    "    \n",
    "    # Print model summary\n",
    "    print(\"\\nModel Summary:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Count parameters\n",
    "    trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
    "    print(f\"\\nTotal trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Visualize augmentation effects\n",
    "    print(\"\\nVisualizing data augmentation effects...\")\n",
    "    visualize_augmentation_effects(model, train_subset[0])\n",
    "    \n",
    "    # Train for 2 epochs\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Starting training for 2 test epochs...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_subset, train_labels_subset,\n",
    "        validation_data=(val_subset, val_labels_subset),\n",
    "        epochs=2,\n",
    "        batch_size=8,  # Small batch size for testing\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot results\n",
    "    print(\"\\nPlotting training history...\")\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Evaluating on validation subset...\")\n",
    "    print(\"=\"*70)\n",
    "    val_loss, val_acc = model.evaluate(val_subset, val_labels_subset, verbose=0)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # Make predictions on a few samples\n",
    "    print(\"\\nMaking predictions on 5 validation samples...\")\n",
    "    predictions = model.predict(val_subset[:5])\n",
    "    \n",
    "    for i in range(5):\n",
    "        pred_class = np.argmax(predictions[i])\n",
    "        true_class = val_labels_subset[i]\n",
    "        confidence = predictions[i][pred_class]\n",
    "        print(f\"Sample {i}: True={true_class}, Predicted={pred_class}, Confidence={confidence:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TEST COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. If training worked, save this notebook\")\n",
    "    print(\"2. Prepare for full training on GPU\")\n",
    "    print(\"3. Use more epochs (50-100) and full dataset\")\n",
    "    print(\"4. Add callbacks: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\")\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c644f35",
   "metadata": {},
   "source": [
    "FULL TRAINING SETUP (For GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bde1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_training_setup():\n",
    "    \"\"\"\n",
    "    Setup for full training on GPU - run this after quick test works\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"FULL TRAINING SETUP (WITH 3D AUGMENTATION)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load full dataset\n",
    "    (train_images, train_labels), (val_images, val_labels), (test_images, test_labels) = load_vesselmnist3d()\n",
    "    \n",
    "    # Build model\n",
    "    num_classes = len(np.unique(train_labels))\n",
    "    model = MyNet3D(num_classes=num_classes)\n",
    "    \n",
    "    # Setup callbacks\n",
    "    callbacks = [\n",
    "        # Reduce learning rate when validation loss plateaus\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Stop training if no improvement\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Save best model\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'best_vesselmnist3d_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # TensorBoard logging\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir='./logs',\n",
    "            histogram_freq=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTraining configuration:\")\n",
    "    print(f\"- Training samples: {len(train_images)}\")\n",
    "    print(f\"- Validation samples: {len(val_images)}\")\n",
    "    print(f\"- Test samples: {len(test_images)}\")\n",
    "    print(f\"- Number of classes: {num_classes}\")\n",
    "    print(f\"- Batch size: 32\")\n",
    "    print(f\"- Max epochs: 100 (with early stopping)\")\n",
    "    print(f\"- Augmentation: ENABLED (3D custom augmentation)\")\n",
    "    \n",
    "    # Train\n",
    "    print(\"\\nStarting full training...\")\n",
    "    history = model.fit(\n",
    "        train_images, train_labels,\n",
    "        validation_data=(val_images, val_labels),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL EVALUATION ON TEST SET\")\n",
    "    print(\"=\"*70)\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    return model, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test \n",
    "print(\"Running quick test training with 3D augmentation...\")\n",
    "model, history = quick_test_training()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc58ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full training\n",
    "# print(\"Running full training...\")\n",
    "# model, history = full_training_setup()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
